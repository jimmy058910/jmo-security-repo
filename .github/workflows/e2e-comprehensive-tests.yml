name: E2E Comprehensive Tests

on:
  pull_request:
    paths:
      - 'scripts/**'
      - 'tests/**'
      - 'pyproject.toml'
      - 'jmo.yml'
      - '.github/workflows/e2e-comprehensive-tests.yml'
  schedule:
    # Nightly at 6 AM UTC
    - cron: '0 6 * * *'
  workflow_dispatch:
    inputs:
      test_id:
        description: 'Specific test to run (e.g., U1, M2, A3). Leave empty for all tests.'
        required: false
        default: ''
      docker_tag:
        description: 'Docker image tag to test'
        required: false
        default: 'latest'

jobs:
  ubuntu-e2e:
    name: Ubuntu E2E Tests
    runs-on: ubuntu-22.04
    timeout-minutes: 180  # 3 hours for full suite

    strategy:
      fail-fast: false
      matrix:
        python-version: ['3.11']

    permissions:
      contents: read
      issues: write
      pull-requests: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v5

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v6
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'

      - name: Install JMo Security
        run: |
          pip install --upgrade pip setuptools wheel
          pip install -e .
          jmo --help || echo "jmo CLI not available"
          jmotools --help || echo "jmotools not available"

      - name: Install external security tools
        run: |
          # Install core tools needed for fast profile
          make tools || echo "Some tools failed to install, continuing..."

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Pull Docker test images
        run: |
          docker pull alpine:3.19
          docker pull nginx:alpine
          docker pull redis:alpine

      - name: Pull JMo Docker images (if testing Docker variants)
        if: github.event.inputs.docker_tag != ''
        run: |
          docker pull ghcr.io/jimmy058910/jmo-security:${{ github.event.inputs.docker_tag }}-full || echo "Full image not found"
          docker pull ghcr.io/jimmy058910/jmo-security:${{ github.event.inputs.docker_tag }}-slim || echo "Slim image not found"
        env:
          DOCKER_TAG: ${{ github.event.inputs.docker_tag }}

      - name: Setup test fixtures
        run: |
          bash tests/e2e/fixtures/setup_fixtures.sh

      - name: Run comprehensive test suite
        id: run_tests
        run: |
          if [[ -n "${{ github.event.inputs.test_id }}" ]]; then
            echo "Running specific test: ${{ github.event.inputs.test_id }}"
            bash tests/e2e/run_comprehensive_tests.sh --test "${{ github.event.inputs.test_id }}"
          else
            echo "Running full Ubuntu + Advanced test suite"
            bash tests/e2e/run_comprehensive_tests.sh
          fi
        env:
          TEST_REPO: https://github.com/juice-shop/juice-shop.git
          TEST_IMAGE: alpine:3.19
          TEST_URL: http://testphp.vulnweb.com
          DOCKER_TAG: ${{ github.event.inputs.docker_tag || 'latest' }}
          RESULTS_BASE: /tmp/jmo-e2e-results-${{ github.run_id }}
        continue-on-error: true

      - name: Generate test report
        if: always()
        run: |
          if [[ -f /tmp/jmo-e2e-results-${{ github.run_id }}/test-results.csv ]]; then
            python tests/e2e/generate_report.py /tmp/jmo-e2e-results-${{ github.run_id }}/test-results.csv
          else
            echo "No test results found"
          fi

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v5
        with:
          name: e2e-test-results-ubuntu-${{ github.run_id }}
          path: |
            /tmp/jmo-e2e-results-${{ github.run_id }}/test-results.csv
            /tmp/jmo-e2e-results-${{ github.run_id }}/*/test.log
            /tmp/jmo-e2e-results-${{ github.run_id }}/*/summaries/findings.json
            /tmp/jmo-e2e-results-${{ github.run_id }}/*/summaries/SUMMARY.md
          retention-days: 30

      - name: Upload test report
        if: always()
        uses: actions/upload-artifact@v5
        with:
          name: e2e-test-report-${{ github.run_id }}
          path: test-report.md
          retention-days: 30

      - name: Comment PR with test results
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v8
        with:
          script: |
            const fs = require('fs');
            let report = '## E2E Comprehensive Test Results\n\n';

            if (fs.existsSync('test-report.md')) {
              report += fs.readFileSync('test-report.md', 'utf8');
            } else {
              report += '⚠️ Test report generation failed. Check workflow logs for details.\n';
            }

            // Add link to full results
            const repoUrl = 'https://github.com/${{ github.repository }}';
            const runUrl = `${repoUrl}/actions/runs/${{ github.run_id }}`;
            report += `\n\n📊 [View full test results artifact](${runUrl})\n`;

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: report
            });

      - name: Check test success
        if: always()
        run: |
          if [[ -f /tmp/jmo-e2e-results-${{ github.run_id }}/test-results.csv ]]; then
            FAILED_TESTS=$(grep -c ",FAIL," /tmp/jmo-e2e-results-${{ github.run_id }}/test-results.csv || echo 0)
            if [[ $FAILED_TESTS -gt 0 ]]; then
              echo "❌ $FAILED_TESTS tests failed"
              exit 1
            else
              echo "✅ All tests passed"
            fi
          else
            echo "❌ No test results found"
            exit 1
          fi

  macos-e2e:
    name: macOS E2E Tests
    runs-on: macos-14
    timeout-minutes: 120  # 2 hours for macOS suite
    if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'

    strategy:
      fail-fast: false
      matrix:
        python-version: ['3.11']

    permissions:
      contents: read

    steps:
      - name: Checkout repository
        uses: actions/checkout@v5

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v6
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'

      - name: Install JMo Security
        run: |
          pip install --upgrade pip setuptools wheel
          pip install -e .

      - name: Install external security tools via Homebrew
        run: |
          # Install core tools for macOS testing
          brew install semgrep trivy syft checkov hadolint || echo "Some tools failed"

      - name: Check Docker availability
        id: check_docker
        run: |
          if command -v docker &> /dev/null; then
            echo "docker_available=true" >> "$GITHUB_OUTPUT"
            echo "✅ Docker is available"
          else
            echo "docker_available=false" >> "$GITHUB_OUTPUT"
            echo "⚠️ Docker is not available on this runner (expected for macOS)"
          fi

      - name: Pull Docker test images
        if: steps.check_docker.outputs.docker_available == 'true'
        run: |
          docker pull alpine:3.19

      - name: Setup test fixtures
        run: |
          bash tests/e2e/fixtures/setup_fixtures.sh

      - name: Run macOS test suite
        run: |
          bash tests/e2e/run_comprehensive_tests.sh
        env:
          TEST_REPO: https://github.com/juice-shop/juice-shop.git
          TEST_IMAGE: alpine:3.19
          DOCKER_TAG: ${{ github.event.inputs.docker_tag || 'latest' }}
          RESULTS_BASE: /tmp/jmo-e2e-results-${{ github.run_id }}
        continue-on-error: true

      - name: Generate test report
        if: always()
        continue-on-error: true
        run: |
          if [[ -f /tmp/jmo-e2e-results-${{ github.run_id }}/test-results.csv ]]; then
            python tests/e2e/generate_report.py /tmp/jmo-e2e-results-${{ github.run_id }}/test-results.csv
          else
            echo "⚠️ No test results CSV found, skipping report generation"
          fi

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v5
        with:
          name: e2e-test-results-macos-${{ github.run_id }}
          path: |
            /tmp/jmo-e2e-results-${{ github.run_id }}/test-results.csv
            /tmp/jmo-e2e-results-${{ github.run_id }}/*/test.log
          retention-days: 30

  summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [ubuntu-e2e]
    if: always()

    steps:
      - name: Download all test results
        uses: actions/download-artifact@v6
        with:
          pattern: e2e-test-results-*
          path: test-results

      - name: Aggregate results
        run: |
          {
            echo "## E2E Test Summary"
            echo ""
          } > summary.md

          for results_file in test-results/*/test-results.csv; do
            if [[ -f "$results_file" ]]; then
              os=$(dirname "$results_file" | xargs basename | cut -d'-' -f4)

              total=$(($(wc -l < "$results_file") - 1))
              passed=$(grep -c ",PASS," "$results_file" || echo 0)
              failed=$(grep -c ",FAIL," "$results_file" || echo 0)
              skipped=$(grep -c ",SKIP," "$results_file" || echo 0)

              {
                echo "### $os Results"
                echo "- Total: $total"
                echo "- Passed: $passed ✅"
                echo "- Failed: $failed ❌"
                echo "- Skipped: $skipped ⏭️"
                echo ""
              } >> summary.md
            fi
          done

          cat summary.md

      - name: Upload summary
        uses: actions/upload-artifact@v5
        with:
          name: test-summary-${{ github.run_id }}
          path: summary.md
          retention-days: 90
